{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spikeinterface'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspikeinterface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msorters\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspikeinterface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfull\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msi\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m  \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msignal\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spikeinterface'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import spikeinterface.sorters\n",
    "import spikeinterface.full as si\n",
    "import  scipy.signal\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.comparison\n",
    "import spikeinterface.exporters\n",
    "import spikeinterface.curation\n",
    "import spikeinterface.widgets \n",
    "import docker\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "import scipy.io as sio\n",
    "import sys\n",
    "import glob\n",
    "import ast\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wavpack_numcodecs import WavPack\n",
    "compressor_wv = WavPack(level=3, bps=None)\n",
    "# The first command-line argument after the script name is the mouse identifier.\n",
    "mouse='M00013'\n",
    "# All command-line arguments after `mouse` and before `save_date` are considered dates.\n",
    "\n",
    "save_date_list=[20250218]\n",
    "\n",
    "base_folder='/run/user/1004/gvfs/smb-share:server=rdp.arc.ucl.ac.uk,share=ritd-ag-e=e=ritd-ag-project-ee=ritd-agee=ritd-ag-project-rd01ie-asale69/ibn-vision/DATA/SUBJECTS/' \n",
    "base_folder='/run/user/1004/gvfs/smb-share:server=rdp.arc.ucl.ac.uk,share=ritd-ag-project-rd01qp-dbend52/Ellie/DATA/SUBJECTS/' \n",
    "no_probe = 2\n",
    "# slice off the reocrding that had failing errors happened during the recording\n",
    "no_dates = len(save_date_list)\n",
    "\n",
    "date_count = 0\n",
    "for save_date_tmp in save_date_list:\n",
    "    save_date = str(save_date_tmp)\n",
    "    recording_folder = base_folder + mouse + '/ephys/' + save_date + '/'\n",
    "    error_info_path = os.path.join(recording_folder, 'error_info.csv')\n",
    "    if os.path.exists(error_info_path):\n",
    "        error_info = pd.read_csv(error_info_path)\n",
    "        print(error_info)\n",
    "    else:\n",
    "        print(f'No error_info.csv found in {recording_folder}')\n",
    "        columns = ['acquisition', 'session', 'error_sample', 'error_timestamp']\n",
    "        error_info = pd.DataFrame(columns=columns)\n",
    "        error_info.to_csv(error_info_path, index=False)\n",
    "        print(f'Created empty error_info.csv in {recording_folder}')\n",
    "    num_rows = len(error_info)\n",
    "    if num_rows > 0:\n",
    "        print('error exists in recordings. Will slice recordings after error happened')\n",
    "        unique_acquisition_indices = error_info.drop_duplicates(subset='acquisition', keep='first').index.tolist()\n",
    "        print(f'Unique acquisition indices: {unique_acquisition_indices}')\n",
    "        acquisition_to_slice = error_info['acquisition'].tolist()\n",
    "        segment_to_slice = error_info['session'].apply(lambda x: int(x[-1])).tolist()\n",
    "        error_sample = error_info['error_sample'].tolist()\n",
    "        acquisition_to_slice = [acquisition_to_slice[i] for i in unique_acquisition_indices]\n",
    "        segment_to_slice = [segment_to_slice[i] for i in unique_acquisition_indices]\n",
    "        error_sample = [error_sample[i] for i in unique_acquisition_indices]\n",
    "    else:\n",
    "        acquisition_to_slice = []\n",
    "        segment_to_slice = []\n",
    "        error_sample = []\n",
    "    acquisition_folders = []\n",
    " \n",
    "    acquisition_base_path = base_folder + mouse + '/ephys/' + save_date + '/*' + save_date\n",
    "    print(acquisition_base_path)\n",
    "    acquisition_folders = glob.glob(acquisition_base_path + '_*')\n",
    "    print('acquisition_folders: ', acquisition_folders)\n",
    " \n",
    "    for probe in range(int(no_probe)):\n",
    "        for acquisition_folder in acquisition_folders:\n",
    "                # Rename all tcat files to t0 if they exist\n",
    "            tcat_pattern = os.path.join(acquisition_folder,'**','*tcat.imec*.lf*')\n",
    "            files_to_rename = glob.glob(tcat_pattern, recursive=True)\n",
    "            # Step 1: Iterate over the list of files with tcat in the name\n",
    "            for old_name in files_to_rename:\n",
    "                # Step 2: Construct the new filename (REMEMBER to switch the name back to tcat)\n",
    "                new_name = old_name.replace('tcat', 't0')\n",
    "                # Step 3: Rename the file\n",
    "                os.rename(old_name, new_name)\n",
    "                print(f'Renamed {old_name} to {new_name}')\n",
    "            recording_raw = si.read_spikeglx(acquisition_folder,stream_name='imec' + str(probe) + '.ap')\n",
    "            no_segments = recording_raw.get_num_segments()\n",
    "            segments = [i for i in range(no_segments)]\n",
    "            num_segments = [recording_raw.get_num_frames(segment_index=i) for i in segments]\n",
    "            end_sample = list(itertools.accumulate(num_segments))\n",
    " \n",
    "            print('reading recording from:', acquisition_folder,'and probe',str(probe))\n",
    "            if any(f'{acq}' in acquisition_folder[-1] for acq in acquisition_to_slice):\n",
    "                print(f'Acquisition {acquisition_folder} corresponds to one of the acquisition_to_slice: {acquisition_to_slice}')\n",
    " \n",
    "                slice_index = acquisition_to_slice.index(int(acquisition_folder[-1]))\n",
    "                sample_index = error_sample[slice_index]\n",
    "                segment_index = segment_to_slice[slice_index]\n",
    "                print(f'Removing samples for acquisition {acquisition_folder[-1]} segment {segment_index} after {sample_index-300000} th sample')\n",
    "                print(f'recording before slicing: {recording_raw}')\n",
    "                selected_segment =  si.select_segment_recording(recording_raw,segment_indices=segment_index)\n",
    "                sliced_segment =selected_segment.frame_slice( start_frame=0, end_frame=sample_index-300000 )\n",
    "                print(f'appending sliced segment from segment {segment_index} to previous recording segment {list(range(segment_index))}')\n",
    "                if segment_index > 0:\n",
    "                    previous_recording = si.select_segment_recording(recording_raw,segment_indices = list(range(segment_index)))\n",
    "                    recording_raw = si.append_recordings([previous_recording,sliced_segment])\n",
    "                else:\n",
    "                    recording_raw = sliced_segment\n",
    "            print(f'sliced recording from acquisition {acquisition_folder}:')\n",
    "            print(recording_raw)\n",
    "            print(recording_raw.get_num_segments)\n",
    "            compression_folder = base_folder + mouse + '/ephys/' + save_date + '/probe' + str(probe) + '_compressed' + acquisition_folder[-2:]\n",
    "            print('compressing to folder: '+compression_folder)\n",
    "            if not os.path.exists(compression_folder + '.zarr'):\n",
    "                print(f'Compression folder {compression_folder} does not exist. Saving compressed recording.')\n",
    "                raw_compressed = recording_raw.save(format=\"zarr\", folder=compression_folder, compressor=compressor_wv, n_jobs=16, chunk_duration=\"1s\")\n",
    "            else:\n",
    "                print(f'Compression folder {compression_folder} already exists. Skipping save.')\n",
    "            tcat_pattern = os.path.join(acquisition_folder, '**', '*t0.imec*.lf*')\n",
    "            files_to_rename = glob.glob(tcat_pattern, recursive=True)\n",
    "            for old_name in files_to_rename:\n",
    "                new_name = old_name.replace('t0', 'tcat')    \n",
    "                os.rename(old_name, new_name)\n",
    "                print(f'Renamed {old_name} to {new_name}')\n",
    "            load_compressed = si.read_zarr(compression_folder+'.zarr')\n",
    "            recording_raw.get_probe().to_dataframe()\n",
    "            fig, ax = plt.subplots(figsize=(15, 10))\n",
    "            si.plot_probe_map(recording_raw, ax=ax)\n",
    "            ax.set_ylim(-100, 4000)\n",
    "    date_count = date_count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write_zarr_recording \n",
      "n_jobs=16 - samples_per_chunk=29,999 - chunk_memory=21.97 MiB - total_memory=351.55 MiB - chunk_duration=1.00s (999.97 ms)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_zarr_recording: 100%|████████████████████████████████████████| 12376/12376 [54:20<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write_zarr_recording \n",
      "n_jobs=16 - samples_per_chunk=29,999 - chunk_memory=21.97 MiB - total_memory=351.55 MiB - chunk_duration=1.00s (999.97 ms)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_zarr_recording: 100%|████████████████████████████████████████| 12376/12376 [59:15<00:00,  3.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import spikeinterface.sorters\n",
    "import spikeinterface.full as si\n",
    "import  scipy.signal\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.comparison\n",
    "import spikeinterface.exporters\n",
    "import spikeinterface.curation\n",
    "import spikeinterface.widgets \n",
    "import docker\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "import scipy.io as sio\n",
    "import sys\n",
    "import glob\n",
    "import ast\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wavpack_numcodecs import WavPack\n",
    "compressor_wv = WavPack(level=3, bps=None)\n",
    "# The first command-line argument after the script name is the mouse identifier.\n",
    "mouse='M24016'\n",
    "# All command-line arguments after `mouse` and before `save_date` are considered dates.\n",
    "\n",
    "save_date_list=[20240625,20240621,20240622,20240624,20240627,20240628,20240701,20240702,20240703]\n",
    "\n",
    "base_folder='/saleem/ibn-vision/DATA/SUBJECTS/' \n",
    "no_probe = 2\n",
    "# slice off the reocrding that had failing errors happened during the recording\n",
    "#acquisition_to_slice = []\n",
    "#slice_time_ranges = []\n",
    "no_dates = len(save_date_list)\n",
    "\n",
    "\n",
    "date_count = 0\n",
    "for save_date_tmp in save_date_list:\n",
    "    acquisition_to_slice = []\n",
    "\n",
    "    save_date = str(save_date_tmp)\n",
    "    recording_folder = base_folder + mouse + '/ephys/' + save_date + '/'\n",
    "    error_info_path = os.path.join(recording_folder, 'error_info.csv')\n",
    "    if os.path.exists(error_info_path):\n",
    "        error_info = pd.read_csv(error_info_path)\n",
    "        print(error_info)\n",
    "    else:\n",
    "        print(f'No error_info.csv found in {recording_folder}')\n",
    "        columns = ['acquisition', 'session', 'error_sample', 'error_timestamp']\n",
    "        error_info = pd.DataFrame(columns=columns)\n",
    "        error_info.to_csv(error_info_path, index=False)\n",
    "        print(f'Created empty error_info.csv in {recording_folder}')\n",
    "    num_rows = len(error_info)\n",
    "    if num_rows > 0:\n",
    "        print('error exists in recordings. Will slice recordings after error happened')\n",
    "        unique_acquisition_indices = error_info.drop_duplicates(subset='acquisition', keep='first').index.tolist()\n",
    "        print(f'Unique acquisition indices: {unique_acquisition_indices}')\n",
    "        acquisition_to_slice = error_info['acquisition'].tolist()\n",
    "        segment_to_slice = error_info['session'].apply(lambda x: int(x[-1])).tolist()\n",
    "        error_sample = error_info['error_sample'].tolist()\n",
    "        acquisition_to_slice = [acquisition_to_slice[i] for i in unique_acquisition_indices]\n",
    "        segment_to_slice = [segment_to_slice[i] for i in unique_acquisition_indices]\n",
    "        error_sample = [error_sample[i] for i in unique_acquisition_indices]\n",
    "    acquisition_folders = []\n",
    "\n",
    "    acquisition_base_path = base_folder + mouse + '/ephys/' + save_date + '/*' + save_date\n",
    "    print(acquisition_base_path)\n",
    "    acquisition_folders = glob.glob(acquisition_base_path + '_*')\n",
    "    print('acquisition_folders: ', acquisition_folders)\n",
    "\n",
    "    for probe in range(int(no_probe)):\n",
    "        for acquisition_folder in acquisition_folders:\n",
    "\n",
    "            tcat_pattern = os.path.join(acquisition_folder, '**', '*t0.imec*.lf*')\n",
    "            files_to_rename = glob.glob(tcat_pattern, recursive=True)\n",
    "            for old_name in files_to_rename:\n",
    "                new_name = old_name.replace('t0', 'tcat')    \n",
    "                os.rename(old_name, new_name)\n",
    "                print(f'Renamed {old_name} to {new_name}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
